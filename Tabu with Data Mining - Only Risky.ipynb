{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5A4VF3loLuO"
   },
   "source": [
    "TABU- HEURISTIC 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3f1efMPWIyu",
    "outputId": "90206e0d-e0a9-4432-abd0-bf952ce96d02"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from networkx import nx\n",
    "from copy import copy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_df=pd.DataFrame(pd.read_csv(\"C:/Users/Lenovo/Desktop/adjacency_df-n100-m400.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(adjacency_df)\n",
    "\n",
    "adjacency_df.columns=(range(1,(n+4)))\n",
    "adjacency_df=adjacency_df.rename(columns={n+1:'Threshold',n+2:'IsInfected', n+3:'IsRisky' },errors='raise')\n",
    "\n",
    "adjacency_df.index=(range(1,(n+1)))\n",
    "\n",
    "m=((adjacency_df.loc[:,range(1,n+1)]>0).sum().sum())/2\n",
    "\n",
    "\n",
    "zeros=[1,0.3,0.1]\n",
    "ones=[1,0.5,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):      \n",
    "    rows, cols = np.where(a.loc[range(1,n+1), range(1,n+1)] > 0)\n",
    "    edges = zip((rows+1).tolist(), (cols+1).tolist())\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "Blocking_Capacity = (int(n/10)*2)\n",
    "step_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets\n",
    "\n",
    "setV = range(1,n+1)\n",
    "setS = adjacency_df.loc[(adjacency_df.loc[:, \"IsInfected\"] < 1),\"IsInfected\"].index.tolist()\n",
    "setP = adjacency_df.loc[(adjacency_df.loc[:, \"IsInfected\"] > 0),\"IsInfected\"].index.tolist()\n",
    "setRisky= adjacency_df.loc[(adjacency_df.loc[:, \"IsRisky\"] > 0),\"IsRisky\"].index.tolist()\n",
    "setS_diff_index=np.array(setS)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(random_state=0,min_impurity_decrease=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "preprocessed_matrix = adjacency_df.copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 infected \n",
    "preprocessed_matrix.loc[setP,setP] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum of all edges lower than threshold (not infected)\n",
    "index = preprocessed_matrix.loc[(preprocessed_matrix[setV].sum(axis=1)<((preprocessed_matrix.loc[:, \"Threshold\"]))) & (preprocessed_matrix.loc[:,\"IsInfected\"]<0.01)  , range(1,n+1)].index\n",
    "preprocessed_matrix.loc[index,setV] = 0\n",
    "preprocessed_matrix.loc[setV,index] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 neighbor (not infected not risky)\n",
    "index2 = preprocessed_matrix.loc[((preprocessed_matrix.loc[setV,setV]>0).sum(axis=1) == 1 & (preprocessed_matrix.loc[:,\"IsInfected\"]<0.01)) & (preprocessed_matrix.loc[:,\"IsRisky\"]<0.01), range(1,n+1)].index\n",
    "preprocessed_matrix.loc[index2,setV] = 0\n",
    "preprocessed_matrix.loc[setV,index2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage assignment\n",
    "preprocessed_matrix.loc[:,setV]=preprocessed_matrix.loc[:,setV].div(preprocessed_matrix.loc[:,\"Threshold\"],axis=0)\n",
    "preprocessed_matrix[preprocessed_matrix[setV] >= 1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonconnected_nodes=preprocessed_matrix.loc[preprocessed_matrix.loc[:,range(1,n+1)].sum(axis=0)==0,:].index\n",
    "for i in nonconnected_nodes:\n",
    "    preprocessed_matrix.at[i,i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!! Edges below %50 influence are deleted !!!!!!!!!!!\n",
    "Graph3=convert(preprocessed_matrix)\n",
    "preprocessed_matrix[preprocessed_matrix[setV] <= 0.3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonconnected_nodes=preprocessed_matrix.loc[preprocessed_matrix.loc[:,range(1,n+1)].sum(axis=0)==0,:].index\n",
    "for i in nonconnected_nodes:\n",
    "    preprocessed_matrix.at[i,i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_matrix.loc[preprocessed_matrix.loc[:,range(1,n+1)].sum(axis=0)==0,:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = convert(preprocessed_matrix)\n",
    "#Graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_paths=[]\n",
    "for starting_nodes in setP:\n",
    "    for ending_nodes in setRisky:\n",
    "        found_paths=found_paths+list(nx.all_simple_paths(Graph, starting_nodes, ending_nodes, cutoff=step_size))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in setP:\n",
    "    found_paths = [[ele for ele in sub if ele != j] for sub in found_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_blocking_capacity=Blocking_Capacity\n",
    "found_paths_removable=found_paths\n",
    "already_blocked_nodes=[]\n",
    "found_paths_np = np.concatenate([np.array(i) for i in found_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_on_paths, total_appearance = np.unique(found_paths_np, return_counts=True)\n",
    "\n",
    "for i in setP:\n",
    "    total_appearance=np.delete(total_appearance, np.where(nodes_on_paths[:] == i))\n",
    "    nodes_on_paths=np.delete(nodes_on_paths, np.where(nodes_on_paths[:] == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_blocked_nodes.append(nodes_on_paths[np.argmax(total_appearance)])\n",
    "remaining_blocking_capacity -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (remaining_blocking_capacity>0):\n",
    "    \n",
    "    \n",
    "    found_paths_removable = list(filter(lambda x: already_blocked_nodes[-1] not in x, found_paths_removable))\n",
    "    \n",
    "    if (len(found_paths_removable)<=0):\n",
    "        remaining_risky=np.array(setRisky)\n",
    "\n",
    "        for i in already_blocked_nodes:\n",
    "            remaining_risky=np.delete(remaining_risky, np.where(remaining_risky[:] == i))\n",
    "\n",
    "        if(len(remaining_risky)>0):\n",
    "            if(len(remaining_risky)>remaining_blocking_capacity):\n",
    "                chosen=(np.random.choice(remaining_risky,size=remaining_blocking_capacity,replace=False))  \n",
    "                for items in chosen:\n",
    "                    already_blocked_nodes.append(items)\n",
    "            else:\n",
    "                 for items in remaining_risky:\n",
    "                    already_blocked_nodes.append(items)   \n",
    "        \n",
    "        break\n",
    "    \n",
    "    found_paths_removable_np = np.concatenate([np.array(i) for i in found_paths_removable])\n",
    "\n",
    "    nodes_on_paths, total_appearance = np.unique(found_paths_removable_np, return_counts=True)\n",
    "\n",
    "    #for i in setP:\n",
    "        #total_appearance=np.delete(total_appearance, np.where(nodes_on_paths[:] == i))\n",
    "        #nodes_on_paths=np.delete(nodes_on_paths, np.where(nodes_on_paths[:] == i))\n",
    "\n",
    "    already_blocked_nodes.append(nodes_on_paths[np.argmax(total_appearance)])\n",
    "    remaining_blocking_capacity -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_nodes = np.zeros(n)\n",
    "#blocked_nodes[nodes_on_paths[np.argpartition(total_appearance, -Blocking_Capacity)[-Blocking_Capacity:]]-1]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_nodes_df=pd.DataFrame(blocked_nodes).T\n",
    "blocked_nodes_df.columns=(range(1,(n+1)))\n",
    "blocked_nodes_df\n",
    "blocked_nodes_df[already_blocked_nodes]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution_for_tabu=blocked_nodes_df.values.tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocked_nodes_df.to_csv('blocked_nodes_df-n'+str(n)+'-m'+str(m)+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LTM(removed_nodes,Graph_for_simulation,setP):\n",
    "    G=Graph_for_simulation.copy()\n",
    "    for i in range(len(removed_nodes)):\n",
    "        if(removed_nodes[i]>0):            \n",
    "            G.remove_node(i+1)\n",
    "    converted_list=setP.copy()\n",
    "    while(1):\n",
    "        #start2=time.time()\n",
    "        converted_list1 = converted_list[:]\n",
    "        #print('step:'+str(converted_list))\n",
    "        for node in G.nodes():\n",
    "            if (node) not in converted_list: \n",
    "                total_weight = 0\n",
    "                for each in G.neighbors(node):\n",
    "                    if (each) in converted_list:\n",
    "                        total_weight = total_weight + adjacency_df.at[node,each]\n",
    "                if total_weight > adjacency_df.at[node,'Threshold']:\n",
    "                    converted_list.append(node)\n",
    "        #end2=time.time()\n",
    "        #print(end2-start2)           \n",
    "        if set(converted_list1) == set(converted_list):\n",
    "            break\n",
    "    objective_value=adjacency_df.loc[converted_list,'IsRisky'].sum()\n",
    "    return objective_value,converted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LTM2(removed_nodes,Graph_for_simulation,setP):\n",
    "    G=Graph_for_simulation.copy()\n",
    "    for i in removed_nodes:           \n",
    "        G.remove_node(i)\n",
    "    converted_list=setP.copy()   \n",
    "    while(1):\n",
    "        converted_list1 = converted_list[:]\n",
    "        for node in G.nodes():\n",
    "            if (node) not in converted_list: \n",
    "                total_weight = 0\n",
    "                for each in G.neighbors(node):\n",
    "                    if (each) in converted_list:\n",
    "                        total_weight = total_weight + adjacency_df.at[node,each]\n",
    "                if total_weight > adjacency_df.at[node,'Threshold']:\n",
    "                    converted_list.append(node)         \n",
    "        if set(converted_list1) == set(converted_list):\n",
    "            break\n",
    "    objective_value=adjacency_df.loc[converted_list,'IsRisky'].sum()\n",
    "    return objective_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeighborEvaluation(plain_converted_list,incumbent_converted_list,incumbent_objective,Exchanged,Neighbor,Graph_for_simulation,setP):\n",
    "    if (Exchanged[1] in plain_converted_list):\n",
    "            for j in range(len(incumbent_converted_list)):\n",
    "                if (incumbent_converted_list[j]==Exchanged[1]):\n",
    "                    new_setP=incumbent_converted_list[:j].copy()\n",
    "                    #print(Exchanged)\n",
    "                    #print('new_setP:')\n",
    "                    #print(new_setP)\n",
    "\n",
    "                    if(incumbent_objective < adjacency_df.loc[new_setP,'IsRisky'].sum()):\n",
    "                        return ((incumbent_objective+1)*10)\n",
    "                    return simulate_LTM(Neighbor,Graph_for_simulation,new_setP)[0]\n",
    "    return incumbent_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeighborhoodSearch(plain_simulation,IncumbentSolution,TabuList,Graph_for_simulation,setP,tree_list):\n",
    "    ZeroIndices = []\n",
    "    OneIndices = []\n",
    "    \n",
    "    incumbent_simulation=simulate_LTM(IncumbentSolution,Graph_for_simulation,setP)\n",
    "    \n",
    "    for i in range(len(IncumbentSolution)):\n",
    "        if IncumbentSolution[i] == 0:\n",
    "            ZeroIndices.append(i)\n",
    "        else:\n",
    "            OneIndices.append(i)\n",
    "    \n",
    "    AllNeighbor = []\n",
    "    AllNeighborObjVals = []\n",
    "    Moves = []\n",
    "    random_ones= random.sample(range(len(OneIndices)),int((len(OneIndices)*ones[0])))\n",
    "    random_zeros= random.sample(range(len(ZeroIndices)),int((len(ZeroIndices)*zeros[0])))\n",
    "    for i in random_ones:\n",
    "        for j in random_zeros:\n",
    "    #for i in range(len(OneIndices)):\n",
    "        #for j in range(len(ZeroIndices)):\n",
    "            if ((ZeroIndices[j]+1) in setRisky):\n",
    "                #print('setP')\n",
    "                #print('____')\n",
    "                #print(setP)\n",
    "                if [OneIndices[i],ZeroIndices[j]] not in TabuList:\n",
    "                    #start=time.time() \n",
    "                    Moves.append([OneIndices[i],ZeroIndices[j]])\n",
    "                    Temp = copy(IncumbentSolution)\n",
    "                    Temp[ZeroIndices[j]] = 1\n",
    "                    Temp[OneIndices[i]] = 0\n",
    "                    Exchanged=[OneIndices[i]+1,ZeroIndices[j]+1]\n",
    "                    TempObjVal = NeighborEvaluation(plain_simulation,incumbent_simulation[1],incumbent_simulation[0],Exchanged,Temp,Graph_for_simulation,setP)                    \n",
    "                    #print(\"TempObjVal:\"+str(TempObjVal))\n",
    "                    AllNeighbor.append(Temp)\n",
    "                    AllNeighborObjVals.append(TempObjVal)\n",
    "                    \n",
    "                    #end=time.time()\n",
    "                    #print(end-start)\n",
    "    tree_input_df = pd.DataFrame(AllNeighbor,columns=range(1,n+1))\n",
    "    tree_target_df = pd.DataFrame(AllNeighborObjVals,columns=[\"Objective\"])\n",
    "    tree_input_df=tree_input_df.astype(\"category\")\n",
    "    clf.fit(tree_input_df[setS],tree_target_df)    \n",
    "    copied_tree = pickle.dumps(clf)\n",
    "    tree_list.append(pickle.loads(copied_tree))\n",
    "    \n",
    "    #print('Tree kuruldu1 '+str(len(tree_target_df)))\n",
    "    BestIndex = AllNeighborObjVals.index(min(AllNeighborObjVals))\n",
    "    BestSolution = AllNeighbor[BestIndex]\n",
    "    BestObjVal = AllNeighborObjVals[BestIndex]\n",
    "    BestMove = Moves[BestIndex]\n",
    "\n",
    "    return BestSolution, BestObjVal, BestMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeighborhoodSearch_dm(plain_simulation,IncumbentSolution,TabuList,Graph_for_simulation,setP,tree_list,exponential_smoothing_parameter):\n",
    "    \n",
    "    \n",
    "    ZeroIndices = []\n",
    "    OneIndices = []\n",
    "    alpha = exponential_smoothing_parameter\n",
    "    predicted_out_counter=0\n",
    "    incumbent_simulation=simulate_LTM(IncumbentSolution,Graph_for_simulation,setP)\n",
    "    \n",
    "    for i in range(len(IncumbentSolution)):\n",
    "        if IncumbentSolution[i] == 0:\n",
    "            ZeroIndices.append(i)\n",
    "        else:\n",
    "            OneIndices.append(i)\n",
    "    \n",
    "    AllNeighbor = []\n",
    "    AllNeighborObjVals = []\n",
    "    Moves = []\n",
    "    random_ones= random.sample(range(len(OneIndices)),int((len(OneIndices)*ones[0])))\n",
    "    random_zeros= random.sample(range(len(ZeroIndices)),int((len(ZeroIndices)*zeros[0])))\n",
    "    for i in random_ones:\n",
    "        for j in random_zeros:\n",
    "    #for i in range(len(OneIndices)):\n",
    "        #for j in range(len(ZeroIndices)):\n",
    "            if ((ZeroIndices[j]+1) in setRisky):\n",
    "                #print('setP')\n",
    "                #print('____')\n",
    "                #print(setP)\n",
    "                if [OneIndices[i],ZeroIndices[j]] not in TabuList:\n",
    "                    Temp = copy(IncumbentSolution)\n",
    "                    Temp[ZeroIndices[j]] = 1\n",
    "                    Temp[OneIndices[i]] = 0\n",
    "                    ### temp df for tree\n",
    "                    temp_np=np.array(Temp)\n",
    "                    prediction_try = temp_np[setS_diff_index]\n",
    "                    prediction_try=prediction_try.reshape(1,-1)\n",
    "                    predicted_by_tree=[]\n",
    "                    prediction=0\n",
    "\n",
    "                    #for trees in tree_list:\n",
    "                        #predicted_by_tree.append(trees.predict(prediction_try))\n",
    "                    #print(\"prediction started\")\n",
    "                    for t in range(len(tree_list)):\n",
    "                        prediction+=tree_list[t].predict(prediction_try)*(((1-alpha)**(len(tree_list)-t-1)))*(alpha)\n",
    "                    #print(\"prediction ended\")\n",
    "                    #print(\"___________________________________________\")\n",
    "                    #print(\"Tree prediction: \" + str(prediction))\n",
    "                    if prediction < incumbent_simulation[0]*(1.0):\n",
    "                        Moves.append([OneIndices[i],ZeroIndices[j]])\n",
    "                        Exchanged=[OneIndices[i]+1,ZeroIndices[j]+1]\n",
    "                        TempObjVal = NeighborEvaluation(plain_simulation,incumbent_simulation[1],incumbent_simulation[0],Exchanged,Temp,Graph_for_simulation,setP)                    \n",
    "                        #print(\"TempObjVal:\"+str(TempObjVal))\n",
    "                        AllNeighbor.append(Temp)\n",
    "                        AllNeighborObjVals.append(TempObjVal)\n",
    "                        #print(\"Simulation: \" + str(TempObjVal))\n",
    "                        #print(\"Difference: \" + str(TempObjVal-prediction))\n",
    "                        #end=time.time()\n",
    "                        #print(end-start)\n",
    "                    else:\n",
    "                        predicted_out_counter += 1\n",
    "                        if (predicted_out_counter == 3):\n",
    "                            predicted_out_counter = 0\n",
    "                            Moves.append([OneIndices[i],ZeroIndices[j]])\n",
    "                            Exchanged=[OneIndices[i]+1,ZeroIndices[j]+1]\n",
    "                            TempObjVal = NeighborEvaluation(plain_simulation,incumbent_simulation[1],incumbent_simulation[0],Exchanged,Temp,Graph_for_simulation,setP)                    \n",
    "                            #print(\"TempObjVal:\"+str(TempObjVal))\n",
    "                            AllNeighbor.append(Temp)\n",
    "                            AllNeighborObjVals.append(TempObjVal)\n",
    "                            #print(\"Simulation of Pred_Out: \" + str(TempObjVal))\n",
    "                            #print(\"Incumbent Threshold: \" + str(incumbent_simulation[0]*(1.1)))\n",
    "                            #print(\"Tree prediction: \" + str(prediction))\n",
    "                            \n",
    "    tree_input_df = pd.DataFrame(AllNeighbor,columns=range(1,n+1))\n",
    "    tree_target_df = pd.DataFrame(AllNeighborObjVals,columns=[\"Objective\"])\n",
    "    tree_input_df=tree_input_df.astype(\"category\")    \n",
    "    clf.fit(tree_input_df[setS],tree_target_df)    \n",
    "    copied_tree = pickle.dumps(clf)\n",
    "    tree_list.append(pickle.loads(copied_tree))\n",
    "    #print('Tree kuruldu2 '+str(len(tree_target_df)))\n",
    "    BestIndex = AllNeighborObjVals.index(min(AllNeighborObjVals))\n",
    "    BestSolution = AllNeighbor[BestIndex]\n",
    "    BestObjVal = AllNeighborObjVals[BestIndex]\n",
    "    BestMove = Moves[BestIndex]\n",
    "\n",
    "    return BestSolution, BestObjVal, BestMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TabuSearchBinarySwap(NumberOfOnes,SpinningLimit,MaxIter,TabuTenure,Graph_for_simulation,setP,initial_solution_for_tabu,plain_simulation,initial_tree,exponential_smoothing_parameter):\n",
    "    \n",
    "    tree_list = []\n",
    "    \n",
    "    \n",
    "    copied_tree = pickle.dumps(clf)\n",
    "    tree_list.append(pickle.loads(copied_tree))\n",
    "    \n",
    "    random.seed(123)\n",
    "    \n",
    "    \n",
    "    InitialSolution = initial_solution_for_tabu.copy() \n",
    "\n",
    "    IncumbentSolution = InitialSolution\n",
    "    IncumbentObjVal = simulate_LTM(IncumbentSolution,Graph_for_simulation,setP)[0]\n",
    "    #print(\"tabuda çıktım\")\n",
    "    BestSolution = IncumbentSolution\n",
    "    BestObjVal = IncumbentObjVal\n",
    "    Trajectory = [IncumbentObjVal]\n",
    "    BestTrajectory = [BestObjVal]\n",
    "    \n",
    "    TabuList = []\n",
    "    #for i in setS:\n",
    "     #   for j in setP:\n",
    "     #       TabuList = [j,i]\n",
    "    \n",
    "    SpinningIndex = 0\n",
    "    Iteration = 0\n",
    "    \n",
    "    start_CPU=time.time()\n",
    "    CPU_time=0\n",
    "    \n",
    "    while ((Iteration < MaxIter) and CPU_time<=7200):\n",
    "        if Iteration < 3 : \n",
    "        #start=time.time()        \n",
    "            Out = NeighborhoodSearch(plain_simulation,IncumbentSolution,TabuList,Graph_for_simulation,setP,tree_list) \n",
    "        else:\n",
    "            Out= NeighborhoodSearch_dm(plain_simulation,IncumbentSolution,TabuList,Graph_for_simulation,setP,tree_list,exponential_smoothing_parameter) \n",
    "            \n",
    "        #print(Out[1])\n",
    "        #end=time.time()\n",
    "        #print(end-start)\n",
    "        BestNeighbor = Out[0]\n",
    "        BestNeighborObjVal = Out[1]\n",
    "        BestNeighborMove = Out[2]\n",
    "        \n",
    "        if BestObjVal <= IncumbentObjVal:\n",
    "            \n",
    "            IncumbentSolution = BestNeighbor\n",
    "            IncumbentObjVal = BestNeighborObjVal\n",
    "            Trajectory.append(IncumbentObjVal)\n",
    "            if IncumbentObjVal < BestObjVal:\n",
    "                BestObjVal = IncumbentObjVal\n",
    "                BestSolution = IncumbentSolution\n",
    "                SpinningIndex = 0\n",
    "            else:\n",
    "                SpinningIndex += 1\n",
    "            BestTrajectory.append(BestObjVal)\n",
    "            TabuList.append(BestNeighborMove)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            Trajectory.append(IncumbentObjVal)\n",
    "            BestTrajectory.append(BestObjVal)\n",
    "            SpinningIndex += 1\n",
    "            \n",
    "            \n",
    "        if len(TabuList) > TabuTenure:\n",
    "            TabuList.pop(0)\n",
    "            \n",
    "        if SpinningIndex > SpinningLimit:\n",
    "            \n",
    "            Iteration = MaxIter\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            Iteration += 1\n",
    "    \n",
    "        end_CPU=time.time()\n",
    "        CPU_time=end_CPU-start_CPU\n",
    "    return BestSolution, BestObjVal, BestTrajectory, Trajectory, TabuList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.01, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=0, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows=n*2\n",
    "all_columns=setS+['Objective']\n",
    "df_for_dm = pd.DataFrame(np.zeros((total_rows,(n-len(setP)+1))),columns=all_columns,index=range(1,total_rows+1))\n",
    "for i in range(1,total_rows+1):\n",
    "    solution_vector=np.random.choice(setS,Blocking_Capacity,replace=False)\n",
    "    df_for_dm.at[i,'Objective']=simulate_LTM2(solution_vector,Graph,setP)\n",
    "    df_for_dm.loc[i,solution_vector]=1\n",
    "InputVars=df_for_dm.iloc[:,:-1]\n",
    "Target=df_for_dm.iloc[:,-1]\n",
    "InputVars=InputVars.astype(\"category\")    \n",
    "clf.fit(InputVars,Target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.plot_tree(clf)\n",
    "#plt.savefig('Tree_2.pdf')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.111018657684326\n"
     ]
    }
   ],
   "source": [
    "SpinningLimit = 5\n",
    "MaxIter = n*5\n",
    "TabuTenure = 20\n",
    "exponential_smoothing_parameter=0.7\n",
    "Graph2 = convert(adjacency_df)\n",
    "bosliste=np.zeros(n).tolist()\n",
    "plain_simulation=simulate_LTM(bosliste,Graph2,setP)[1]\n",
    "start1=time.time()\n",
    "Tabu_Results = TabuSearchBinarySwap(Blocking_Capacity,SpinningLimit,MaxIter,TabuTenure,Graph2,setP,initial_solution_for_tabu,plain_simulation,clf,exponential_smoothing_parameter)\n",
    "end1=time.time()\n",
    "print(end1-start1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABU ONLY RISKY OBJECTIVE VALUE: 10.0\n"
     ]
    }
   ],
   "source": [
    "print('TABU ONLY RISKY OBJECTIVE VALUE: '+str(Tabu_Results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABU ONLY RISKY TIME: 3.111018657684326\n"
     ]
    }
   ],
   "source": [
    "print('TABU ONLY RISKY TIME: '+str(end1-start1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graph_Generation_for_Math_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
