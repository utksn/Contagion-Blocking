{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5A4VF3loLuO"
   },
   "source": [
    "CONTAGION \n",
    "NODE BLOCKING\n",
    "ERDOS-RENYI GRAPH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3f1efMPWIyu",
    "outputId": "90206e0d-e0a9-4432-abd0-bf952ce96d02"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from networkx import nx\n",
    "import numpy as np\n",
    "import algorithmx\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "list_n=[100,500]\n",
    "list_m=[400,2000]\n",
    "# percentage listler büyükten küçüğe olmak zorunda!!!!\n",
    "infected_percentage_list = [0.15,0.1,0.05]\n",
    "risky_percentage_list = [0.6,0.5,0.4,0.3]\n",
    "name = \"utku\"\n",
    "\n",
    "\n",
    "### node features klasörü açmayı unutma\n",
    "### node features klasörü açmayı unutma\n",
    "for elem in range(len(list_n)):\n",
    "    random.seed(elem)\n",
    "    n=list_n[elem]\n",
    "    m=list_m[elem]\n",
    "    G = nx.gnm_random_graph(n, m)\n",
    "    colnames=range(1,(n+1))\n",
    "    adjacency_df = pd.DataFrame(np.zeros((n,n)),columns=colnames,index=colnames)\n",
    "\n",
    "    for (u, v) in G.edges():\n",
    "        G.edges[u,v]['weight'] = np.random.randint(0,1000)/1000\n",
    "        adjacency_df.iat[u,v]=G.edges[u,v]['weight']\n",
    "        adjacency_df.iat[v,u]=G.edges[u,v]['weight']\n",
    "    adjacency_df['Threshold']=np.random.randint(0,1000,size=n).astype(\"float\")/1000 #Tekrar bak ...\n",
    "    adjacency_df['IsInfected']=np.zeros((n,1))\n",
    "    adjacency_df['IsRisky']=np.zeros((n,1))\n",
    "    adjacency_df_original = adjacency_df.copy(deep=True)\n",
    "    \n",
    "    dummy_vector_for_selection=np.arange(1,n+1)\n",
    "    max_infected = int(infected_percentage_list[0]*n)\n",
    "    max_risky = int(risky_percentage_list[0]*n)\n",
    "    pool_for_all = np.random.choice(dummy_vector_for_selection,(max_infected+max_risky),replace=False)\n",
    "    pool_for_infected = np.random.choice(pool_for_all,max_infected,replace=False)\n",
    "    pool_for_risky = [risk for risk in pool_for_all if risk not in pool_for_infected]\n",
    "    for inf_rate in infected_percentage_list:\n",
    "        for risky_rate in risky_percentage_list:\n",
    "            \n",
    "            infected_percentage=inf_rate\n",
    "            total_risky_percentage=1-infected_percentage\n",
    "            risky_percentage=risky_rate\n",
    "\n",
    "            total_infected=int(infected_percentage*n)\n",
    "            total_risky=int(risky_percentage*n)\n",
    "            #nx.draw(G)\n",
    "            #plt.show()\n",
    "            selected_infected=pool_for_infected[:total_infected]\n",
    "            selected_risky=pool_for_risky[:total_risky]\n",
    "            \n",
    "\n",
    "            adjacency_df=adjacency_df_original.copy(deep=True)\n",
    "            adjacency_df.loc[selected_infected,'IsInfected']=1\n",
    "            adjacency_df.loc[selected_risky,'IsRisky']=1\n",
    "\n",
    "            os.chdir(\"C:\\\\Users\\\\utku\\\\Desktop\\\\bitirme\\\\data\\\\adjaceny_df\")\n",
    "            \n",
    "            adjacency_df.to_csv(\"adjacency_df-n\"+str(n)+'-m'+str(m)+'-run'+str(elem+1)+\"-risky\"+str(int(risky_rate*100))+\"-inf\"+str(int(inf_rate*100))+\"_\"+str(name)+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connectivity=nx.connectivity(Di_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list(nx.bridges(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list(nx.enumerate_all_cliques(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "c = list(greedy_modularity_communities(Di_G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(setRisky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from networkx.algorithms.community import girvan_newman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comp = girvan_newman(Di_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from networkx.algorithms.community.label_propagation import label_propagation_communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comm = label_propagation_communities(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            setV = range(1,n+1)\n",
    "            impact_matrix = adjacency_df.copy(deep=True)\n",
    "            impact_matrix.loc[:,setV]=impact_matrix.loc[:,setV].div(impact_matrix.loc[:,\"Threshold\"],axis=0)\n",
    "            impact_matrix[impact_matrix[setV] >= 1] = 1\n",
    "            Di_G = nx.DiGraph(G)\n",
    "            for (u, v) in G.edges():\n",
    "                Di_G.edges[u,v]['weight'] = impact_matrix.iat[v,u]\n",
    "                Di_G.edges[v,u]['weight'] = impact_matrix.iat[u,v]\n",
    "            node_features=pd.DataFrame(np.zeros((n,1)),columns=[\"IsInfected\"],index=range(1,n+1))\n",
    "            betweenness_cent=nx.betweenness_centrality(Di_G)\n",
    "            degree_cent=nx.degree_centrality(Di_G)\n",
    "            closeness_cent=nx.closeness_centrality(Di_G)\n",
    "            eigenvector_cent=nx.eigenvector_centrality(Di_G)\n",
    "            degree=Di_G.degree()\n",
    "            node_features['IsInfected']=adjacency_df['IsInfected']\n",
    "            node_features['IsRisky']=adjacency_df['IsRisky']\n",
    "            node_features['map_for_dict']=betweenness_cent\n",
    "            node_features['Betweenness']=node_features['map_for_dict'].map(betweenness_cent)\n",
    "            node_features['Degree_Cent']=node_features['map_for_dict'].map(degree_cent)\n",
    "            node_features['Closeness_cent']=node_features['map_for_dict'].map(closeness_cent)\n",
    "            node_features['Eigenvector_cent']=node_features['map_for_dict'].map(eigenvector_cent)\n",
    "            node_features['Degree']=node_features['map_for_dict'].map(degree)\n",
    "            #sets\n",
    "            setS = node_features.loc[(node_features.loc[:, \"IsInfected\"] < 1),\"IsInfected\"].index.tolist()\n",
    "            setP = node_features.loc[(node_features.loc[:, \"IsInfected\"] > 0),\"IsInfected\"].index.tolist()\n",
    "            setRisky= node_features.loc[(node_features.loc[:, \"IsRisky\"] > 0),\"IsRisky\"].index.tolist()\n",
    "            node_features['Shortest_to_Infected']=9999\n",
    "            node_features['Shortest_to_Risky']=0\n",
    "            for i in setS:\n",
    "                shortest_inf=np.array([9999])\n",
    "                shortest_risky=np.array([9999])\n",
    "                for j in setP:\n",
    "                    if(nx.has_path(Di_G,source=i-1,target=j-1)):\n",
    "                        shortest_inf=np.append(shortest_inf,nx.shortest_path_length(Di_G,source=i-1,target=j-1))\n",
    "                node_features.at[i,'Shortest_to_Infected']=shortest_inf.min()\n",
    "                for k in setRisky:\n",
    "                    if(nx.has_path(Di_G,source=i-1,target=k-1)):\n",
    "                        shortest_risky=np.append(shortest_risky,nx.shortest_path_length(Di_G,source=i-1,target=k-1))\n",
    "                node_features.at[i,'Shortest_to_Risky']=shortest_risky.min()\n",
    "            node_features['Total_Impact_Ratio']=impact_matrix[setV].sum(axis=1)\n",
    "            os.chdir(\"C:\\\\Users\\\\utku\\\\Desktop\\\\bitirme\\\\data\\\\node_features\")\n",
    "            #node_features.to_csv(\"node_features-n\"+str(n)+'-m'+str(m)+'-run'+str(elem+1)+\"-risky\"+str(risky_rate*100)+\"-inf\"+str(inf_rate*100)+\"_\"+str(name)+\".csv\",index=False)\n",
    "            node_features.to_csv(\"node_features-n\"+str(n)+'-m'+str(m)+'-run'+str(elem+1)+\"-risky\"+str(int(risky_rate*100))+\"-inf\"+str(int(inf_rate*100))+\"_\"+str(name)+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graph_Generation_for_Math_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
